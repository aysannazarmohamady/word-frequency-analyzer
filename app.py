import streamlit as st
import pandas as pd
import re
from collections import Counter
from itertools import combinations
import numpy as np

# ุชูุธูุงุช ุตูุญู
st.set_page_config(
    page_title="ุชุญูู ูุฑฺฉุงูุณ ฺฉููุงุช",
    page_icon="๐",
    layout="wide"
)

# ุงุณุชุงู CSS ุจุฑุง ุตูุญู ุขุจ ุชุฑู
st.markdown("""
<style>
    .stApp {
        background-color: #1e3a8a;
        color: white;
    }
    .stSelectbox > div > div {
        background-color: #3b82f6;
        color: white;
    }
    .stFileUploader > div {
        background-color: #3b82f6;
        border: 2px dashed #60a5fa;
        border-radius: 10px;
        padding: 20px;
    }
    .stDataFrame {
        background-color: white;
        border-radius: 10px;
        padding: 10px;
    }
    h1, h2, h3 {
        color: #f8fafc;
    }
    .stButton > button {
        background-color: #3b82f6;
        color: white;
        border: none;
        border-radius: 5px;
        padding: 10px 20px;
    }
    .stButton > button:hover {
        background-color: #2563eb;
    }
</style>
""", unsafe_allow_html=True)

def clean_text(text):
    """ุชูุฒ ฺฉุฑุฏู ูุชู ุงุฒ ฺฉุงุฑุงฺฉุชุฑูุง ุบุฑุถุฑูุฑ"""
    if pd.isna(text):
        return ""
    
    # ุญุฐู ฺฉุงุฑุงฺฉุชุฑูุง ุฎุงุต ู ูฺฏู ุฏุงุดุชู ููุท ุญุฑูู ูุงุฑุณุ ุงูฺฏูุณ ู ุงุนุฏุงุฏ
    text = str(text)
    text = re.sub(r'[^\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF\uFB50-\uFDFF\uFE70-\uFEFF\w\s]', ' ', text)
    
    # ุญุฐู ูุงุตููโูุง ุงุถุงู
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text

def get_stopwords():
    """ูุณุช ฺฉููุงุช ุบุฑููุฏ ูุงุฑุณ ู ุงูฺฏูุณ"""
    persian_stopwords = {
        # ุญุฑูู ุงุถุงูู
        'ุงุฒ', 'ุจู', 'ุฏุฑ', 'ุจุง', 'ุชุง', 'ุจุฑุง', 'ุจุฑ', 'ุฑู', 'ุฒุฑ', 'ฺฉูุงุฑ', 'ูุฒุฏ', 'ูพุด', 'ุจุนุฏ', 'ูุจู',
        'ุฌูู', 'ุนูุจ', 'ุจุงูุง', 'ูพุงู', 'ุฏุงุฎู', 'ุฎุงุฑุฌ', 'ูุงู', 'ูุงููุฏ', 'ููฺูู',
        'ูุธุฑ', 'ฺูู', 'ูุซู', 'ุณู', 'ุทุฑู', 'ุณูุช', 'ุฌุงูุจ', 'ูุงุญู', 'ุญูุงู', 'ุงุทุฑุงู', 'ุฏูุฑ',
        
        # ุญุฑูู ุฑุจุท
        'ู', 'ุง', 'ุงูุง', 'ูู', 'ูฺฉู', 'ููฺฉู', 'ุงฺฏุฑ', 'ุงฺฏุฑฺู', 'ฺฏุฑฺู', 'ูุฑฺูุฏ', 'ฺููฺฉู', 'ุฒุฑุง',
        'ูพุณ', 'ุจูุงุจุฑุงู', 'ูุฐุง', 'ูฺฉู', 'ูู', 'ูุฒ', 'ุงูุจุชู', 'ุถููุงู', 'ููฺูู', 'ุนูุงูู', 'ุงูุฒูู',
        'ฺฉู', 'ุชุง', 'ููุช', 'ุฒูุงู', 'ููฺฏุงู', 'ฺู', 'ุขุง', 'ฺฉุฌุง', 'ฺฉ', 'ฺุฑุง', 'ฺฺฏููู', 'ฺุทูุฑ',
        
        # ูุนูโูุง ฺฉูฺฉ ู ุฑุงุฌ
        'ุงุณุช', 'ุจูุฏ', 'ุจุงุดุฏ', 'ุดุฏ', 'ุดุฏู', 'ูโุดูุฏ', 'ูุดูุฏ', 'ุฎูุงูุฏ', 'ุฏุงุฑุฏ', 'ุฏุงุดุช', 'ฺฉุฑุฏ', 'ฺฉุฑุฏู',
        'ูโฺฉูุฏ', 'ูฺฉูุฏ', 'ูโฺฉุฑุฏ', 'ูฺฉุฑุฏ', 'ุจฺฉูุฏ', 'ฺฉูุฏ', 'ูฺฉูุฏ', 'ูุณุช', 'ูุณุช', 'ุจูุฏู', 'ูุจูุฏู',
        'ฺฏูุช', 'ฺฏูุชู', 'ูโฺฏูุฏ', 'ูฺฏูุฏ', 'ุจฺฏูุฏ', 'ุฑูุช', 'ุฑูุชู', 'ูโุฑูุฏ', 'ูุฑูุฏ', 'ุจุฑูุฏ',
        'ุขูุฏ', 'ุขูุฏู', 'ูโุขุฏ', 'ูุขุฏ', 'ุจุงุฏ', 'ุฏุฏ', 'ุฏุฏู', 'ูโุจูุฏ', 'ูุจูุฏ', 'ุจุจูุฏ',
        'ุดูุฏ', 'ูุดูุฏ', 'ุจุดูุฏ', 'ุจุงุฏ', 'ูุจุงุฏ', 'ุจุงุดุฏ', 'ูุจุงุดุฏ', 'ฺฉูุฏ', 'ูฺฉูุฏ', 'ุจฺฉูุฏ',
        
        # ุถูุงุฑ
        'ูู', 'ุชู', 'ุงู', 'ูุง', 'ุดูุง', 'ุขููุง', 'ุงู', 'ุขู', 'ุขูุงู', 'ุงุดุงู', 'ู', 'ุฎูุฏ', 'ุฎูุฏุช',
        'ุฎูุฏุด', 'ุฎูุฏูุงู', 'ุฎูุฏุชุงู', 'ุฎูุฏุดุงู', 'ูู', 'ูุฑ', 'ููู', 'ููฺฏ', 'ุจุฑุฎ', 'ุจุนุถ', 'ฺูุฏ',
        'ฺฉุณ', 'ฺฉุณุงู', 'ฺฉ', 'ุฏฺฏุฑ', 'ุณุงุฑ', 'ุณุงุฑู', 'ุฏฺฏุฑุงู', 'ุบุฑ', 'ุฌุฒ', 'ุจุฌุฒ', 'ูฺฏุฑ'
        
        # ฺฉููุงุช ุชุฃฺฉุฏ ู ูพุฑฺฉููุฏู
        'ุฎู', 'ุจุณุงุฑ', 'ุฒุงุฏ', 'ฺฉู', 'ุงูุฏฺฉ', 'ููุท', 'ุชููุง', 'ุญุช', 'ูููุฒ', 'ุฏฺฏุฑ', 'ุจุงุฒ', 'ุจุงุฒูู',
        'ุฏูุจุงุฑู', 'ูุฌุฏุฏ', 'ุงุตูุงู', 'ฺฉูุงู', 'ฺฉุงููุงู', 'ุชูุงูุงู', 'ูุงูุนุงู', 'ุญููุชุงู', 'ุฑุงุณุช', 'ุงูุจุชู',
        'ูุทูุฆูุงู', 'ุญุชูุงู', 'ูุทุนุงู', 'ููุงู', 'ุงุญุชูุงูุงู', 'ุดุงุฏ', 'ููฺฉู', 'ุงูฺฉุงู', 'ุธุงูุฑุงู', 'ฺฏูุง'
        
        # ุญุฑูู ุงููุจุง ุชฺฉ
        'ุงูู', 'ุจ', 'ูพ', 'ุช', 'ุซ', 'ุฌ', 'ฺ', 'ุญ', 'ุฎ', 'ุฏ', 'ุฐ', 'ุฑ', 'ุฒ', 'ฺ', 'ุณ', 'ุด',
        'ุต', 'ุถ', 'ุท', 'ุธ', 'ุน', 'ุบ', 'ู', 'ู', 'ฺฉ', 'ฺฏ', 'ู', 'ู', 'ู', 'ู', 'ู', ''
    }
    
    english_stopwords = {
        'a', 'an', 'and', 'are', 'as', 'at', 'be', 'been', 'by', 'for', 'from', 'has', 'he',
        'in', 'is', 'it', 'its', 'of', 'on', 'that', 'the', 'to', 'was', 'will', 'with',
        'the', 'be', 'to', 'of', 'and', 'a', 'in', 'that', 'have', 'i', 'it', 'for',
        'not', 'on', 'with', 'he', 'as', 'you', 'do', 'at', 'this', 'but', 'his', 'by',
        'from', 'they', 'we', 'say', 'her', 'she', 'or', 'an', 'will', 'my', 'one', 'all',
        'would', 'there', 'their', 'what', 'so', 'up', 'out', 'if', 'about', 'who', 'get',
        'which', 'go', 'me', 'when', 'make', 'can', 'like', 'time', 'no', 'just', 'him',
        'know', 'take', 'people', 'into', 'year', 'your', 'good', 'some', 'could', 'them',
        'see', 'other', 'than', 'then', 'now', 'look', 'only', 'come', 'its', 'over',
        'think', 'also', 'back', 'after', 'use', 'two', 'how', 'our', 'work', 'first',
        'well', 'way', 'even', 'new', 'want', 'because', 'any', 'these', 'give', 'day',
        'most', 'us', 'is', 'was', 'are', 'been', 'have', 'had', 'has', 'do', 'does',
        'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'shall',
        'am', 'is', 'are', 'was', 'were', 'being', 'been', 'have', 'has', 'had', 'having'
    }
    
    return persian_stopwords.union(english_stopwords)

def get_word_frequency(text_series, n_gram=1, top_n=20, custom_stopwords="", min_length=2):
    """ูุญุงุณุจู ูุฑฺฉุงูุณ ฺฉููุงุช"""
    stopwords = get_stopwords()
    
    # ุงุถุงูู ฺฉุฑุฏู ฺฉููุงุช ุงุถุงู ฺฉุงุฑุจุฑ
    if custom_stopwords.strip():
        user_stopwords = [word.strip() for word in custom_stopwords.split(',')]
        stopwords.update(user_stopwords)
    
    all_words = []
    
    for text in text_series:
        cleaned_text = clean_text(text)
        if cleaned_text:
            words = cleaned_text.split()
            # ุญุฐู ฺฉููุงุช ุบุฑููุฏ ู ฺฉูุชุงู
            words = [word for word in words if 
                    word.lower() not in stopwords and 
                    len(word) >= min_length and 
                    word.strip()]
            
            if n_gram == 1:
                all_words.extend(words)
            elif n_gram == 2:
                # ุฏู ฺฉูููโุง - ุงฺฏุฑ ูุฑ ุฏู ฺฉููู ููุฏ ุจุงุดูุฏ
                for i in range(len(words) - 1):
                    bigram = f"{words[i]} {words[i+1]}"
                    all_words.append(bigram)
            elif n_gram == 3:
                # ุณู ฺฉูููโุง - ุงฺฏุฑ ูุฑ ุณู ฺฉููู ููุฏ ุจุงุดูุฏ
                for i in range(len(words) - 2):
                    trigram = f"{words[i]} {words[i+1]} {words[i+2]}"
                    all_words.append(trigram)
    
    # ุญุฐู ฺฉููุงุช ุฎุงู
    all_words = [word for word in all_words if word.strip()]
    
    # ูุญุงุณุจู ูุฑฺฉุงูุณ
    word_freq = Counter(all_words)
    
    # ฺฏุฑูุชู top_n ฺฉููู ูพุฑูุฑฺฉุงูุณ
    top_words = word_freq.most_common(top_n)
    
    return top_words

def main():
    st.title("๐ ุชุญูู ูุฑฺฉุงูุณ ฺฉููุงุช ุงุฒ ูุงู ุงฺฉุณู")
    st.markdown("---")
    
    # ุฑุงูููุง ุงุณุชูุงุฏู
    st.markdown("""
    ### ๐ ุฑุงูููุง ุงุณุชูุงุฏู:
    1. ูุงู ุงฺฉุณู ุฎูุฏ ุฑุง ุขูพููุฏ ฺฉูุฏ
    2. ููุน ุชุญูู (ุชฺฉ ฺฉูููุ ุฏู ฺฉูููุ ุณู ฺฉููู) ุฑุง ุงูุชุฎุงุจ ฺฉูุฏ
    3. ุณุชูู ููุฑุฏ ูุธุฑ ุฑุง ุงูุชุฎุงุจ ฺฉูุฏ
    4. ุชุนุฏุงุฏ ฺฉููุงุช ูพุฑูุฑฺฉุงูุณ ุฑุง ูุดุฎุต ฺฉูุฏ
    """)
    
    # ุขูพููุฏ ูุงู
    uploaded_file = st.file_uploader(
        "๐ ุจุฑุง ุณุงุฎุชู ุงุจุฑ ฺฉููุงุช ุชุชุฑูุงุ ูุงู ุงฺฉุณู ุฎูุฏ ุฑุง ุงูพููุฏ ฺฉูุฏ",
        type=['xlsx', 'xls'],
        help="ูุงู ุงฺฉุณู ุฎูุฏ ุฑุง ุงูุชุฎุงุจ ฺฉูุฏ"
    )
    
    if uploaded_file is not None:
        try:
            # ุฎูุงูุฏู ูุงู ุงฺฉุณู
            df = pd.read_excel(uploaded_file, header=1)  # ุณุทุฑ 2 ุจู ุนููุงู header
            
            st.success("โ ูุงู ุจุง ููููุช ุขูพููุฏ ุดุฏ!")
            
            # ููุงุด ุงุทูุงุนุงุช ฺฉู ูุงู
            st.markdown(f"**ุชุนุฏุงุฏ ุณุทุฑูุง:** {len(df)}")
            st.markdown(f"**ุชุนุฏุงุฏ ุณุชููโูุง:** {len(df.columns)}")
            
            # ููุงุด ููููู ุฏุงุฏูโูุง
            with st.expander("๐๏ธ ููุงุด ููููู ุฏุงุฏูโูุง"):
                st.dataframe(df.head())
            
            # ุงูุชุฎุงุจ ููุน ุชุญูู
            st.markdown("### ๐ฏ ุงูุชุฎุงุจ ููุน ุชุญูู")
            
            analysis_options = {
                "ุชฺฉ ฺฉูููโุง": [1],
                "ุฏู ฺฉูููโุง": [2],
                "ุณู ฺฉูููโุง": [3],
                "ุชฺฉ ฺฉูููโุง + ุฏู ฺฉูููโุง": [1, 2],
                "ุฏู ฺฉูููโุง + ุณู ฺฉูููโุง": [2, 3],
                "ุชฺฉ ฺฉูููโุง + ุณู ฺฉูููโุง": [1, 3],
                "ูุฑ ุณู ููุน": [1, 2, 3]
            }
            
            selected_analysis = st.selectbox(
                "ูุฎูุงูุฏ ฺู ููุน ุนุจุงุฑุชโูุง ุฑุง ูพุฏุง ฺฉูุฏุ",
                options=list(analysis_options.keys()),
                index=0
            )
            
            # ุงูุชุฎุงุจ ุณุชูู
            st.markdown("### ๐ ุงูุชุฎุงุจ ุณุชูู")
            selected_column = st.selectbox(
                "ุณุชูู ุฑุง ฺฉู ูุฎูุงูุฏ ูุฑฺฉุงูุณ ฺฉููุงุช ุขู ูพุฏุง ุดูุฏ ุงูุชุฎุงุจ ฺฉูุฏ:",
                options=df.columns.tolist(),
                index=0
            )
            
            # ุงูุชุฎุงุจ ุชุนุฏุงุฏ ฺฉููุงุช
            st.markdown("### ๐ข ุชุนุฏุงุฏ ฺฉููุงุช")
            top_n = st.slider(
                "ุชุนุฏุงุฏ ฺฉููุงุช ูพุฑูุฑฺฉุงูุณ:",
                min_value=5,
                max_value=50,
                value=20,
                step=5
            )
            
            # ุชูุธูุงุช ููุชุฑ ฺฉููุงุช
            st.markdown("### ๐ซ ููุชุฑ ฺฉููุงุช")
            with st.expander("ุชูุธูุงุช ูพุดุฑูุชู ููุชุฑ"):
                st.info("๐ก ุจู ุทูุฑ ูพุดโูุฑุถุ ุญุฑูู ุงุถุงููุ ูุนูโูุง ฺฉูฺฉุ ุญุฑูู ุฑุจุท ู ุถูุงุฑ ุญุฐู ูโุดููุฏ")
                
                # ฺฉููุงุช ุงุถุงู ุจุฑุง ุญุฐู
                custom_stopwords = st.text_area(
                    "ฺฉููุงุช ุงุถุงู ุจุฑุง ุญุฐู (ุจุง ฺฉุงูุง ุฌุฏุง ฺฉูุฏ):",
                    placeholder="ูุซุงู: ุดุฑฺฉุชุ ุณุงุฒูุงูุ ุงุฏุงุฑู",
                    height=100,
                    help="ฺฉููุงุช ุฎุงุต ุฎูุฏ ุฑุง ฺฉู ููโุฎูุงูุฏ ุฏุฑ ูุชุงุฌ ุจุงุดูุฏ ูุงุฑุฏ ฺฉูุฏ"
                )
                
                # ุญุฏุงูู ุทูู ฺฉููู
                min_word_length = st.slider(
                    "ุญุฏุงูู ุทูู ฺฉููู:",
                    min_value=1,
                    max_value=5,
                    value=2,
                    help="ฺฉููุงุช ฺฉูุชุงูโุชุฑ ุงุฒ ุงู ุชุนุฏุงุฏ ุญุฑู ุญุฐู ูโุดููุฏ"
                )
            
            # ุฏฺฉูู ุชุญูู
            if st.button("๐ ุดุฑูุน ุชุญูู", type="primary"):
                if selected_column in df.columns:
                    # ุชุญูู ุจุฑ ุงุณุงุณ ุงูุชุฎุงุจ ฺฉุงุฑุจุฑ
                    n_grams = analysis_options[selected_analysis]
                    
                    st.markdown("---")
                    st.markdown("## ๐ ูุชุงุฌ ุชุญูู")
                    
                    for n_gram in n_grams:
                        # ูุญุงุณุจู ูุฑฺฉุงูุณ
                        word_freq = get_word_frequency(
                            df[selected_column], 
                            n_gram=n_gram, 
                            top_n=top_n,
                            custom_stopwords=custom_stopwords,
                            min_length=min_word_length
                        )
                        
                        if word_freq:
                            # ูุงู ููุน ุชุญูู
                            analysis_type = {1: "ุชฺฉ ฺฉูููโุง", 2: "ุฏู ฺฉูููโุง", 3: "ุณู ฺฉูููโุง"}
                            
                            st.markdown(f"### ๐ ูุฑฺฉุงูุณ ฺฉููุงุช {analysis_type[n_gram]}")
                            
                            # ุงุฌุงุฏ ุฌุฏูู
                            freq_df = pd.DataFrame(word_freq, columns=['ฺฉููู/ุนุจุงุฑุช', 'ูุฑฺฉุงูุณ'])
                            freq_df['ุฑุชุจู'] = range(1, len(freq_df) + 1)
                            freq_df = freq_df[['ุฑุชุจู', 'ฺฉููู/ุนุจุงุฑุช', 'ูุฑฺฉุงูุณ']]
                            
                            # ููุงุด ุฌุฏูู
                            st.dataframe(
                                freq_df,
                                use_container_width=True,
                                hide_index=True
                            )
                            
                            # ููุงุด ุขูุงุฑ ฺฉู
                            total_words = sum([freq for _, freq in word_freq])
                            st.markdown(f"**ูุฌููุน ฺฉููุงุช/ุนุจุงุฑุงุช ุงูุช ุดุฏู:** {total_words}")
                            st.markdown(f"**ุชุนุฏุงุฏ ฺฉููุงุช/ุนุจุงุฑุงุช ููุญุตุฑ ุจู ูุฑุฏ:** {len(word_freq)}")
                            
                            # ุฏฺฉูู ุฏุงูููุฏ
                            csv = freq_df.to_csv(index=False, encoding='utf-8-sig')
                            st.download_button(
                                label=f"๐พ ุฏุงูููุฏ ุฌุฏูู {analysis_type[n_gram]}",
                                data=csv,
                                file_name=f"word_frequency_{analysis_type[n_gram]}.csv",
                                mime="text/csv"
                            )
                            
                            st.markdown("---")
                        else:
                            st.warning(f"ูฺ ฺฉูููโุง ุจุฑุง ุชุญูู {analysis_type[n_gram]} ุงูุช ูุดุฏ!")
                else:
                    st.error("ุณุชูู ุงูุชุฎุงุจ ุดุฏู ุฏุฑ ูุงู ููุฌูุฏ ูุณุช!")
        
        except Exception as e:
            st.error(f"ุฎุทุง ุฏุฑ ุฎูุงูุฏู ูุงู: {str(e)}")
            st.info("ูุทูุงู ูุทูุฆู ุดูุฏ ฺฉู ูุงู ุงฺฉุณู ูุนุชุจุฑ ุงุณุช ู ุญุงู ุฏุงุฏู ุงุณุช.")

if __name__ == "__main__":
    main()
